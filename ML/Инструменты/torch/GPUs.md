> https://developer.nvidia.com/cuda-downloads

- `nvidia-smi` - для вывода информации о GPU
- В pytorch у каждого массива есть устройство -> context. 
	- Получение устройств:
		- `torch.device('cpu')`
		- `torch.device('cuda')` `(= torch.device('gpu') = torch.device('gpu:0'))` или `torch.device(f'cuda:{i}')`, если имеется несколько графических процессоров
	- Получение кол-ва доступных GPUs:
		- `torch.cuda.device_count()`
	- Получение контекста массива:
		- `x = torch.tensor([1, 2, 3])`
		   `x.device`
	- Указание устройства, к которому привязан тензор:
		- `X = torch.ones(2, 3, device=try_gpu())`
		- *Нужно следить, что создаваемые данные не привышают лимит памяти GPU*
	- Модели нейронных сетей также имеют конкретное утройство. Перемещение параметров модели в GPU:
	  `net = nn.Sequential(nn.LazyLinear(1))`
	  `net = net.to(device=try_gpu())`
	  `net(X)`
		- Далее как параметры модели, так и входные данные, должны находится на одном устройстве, иначе (*RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)*)
> ! *Нужно следить, чтобы тензоры находились на одном устройстве во время бинарного вычисления* -> иначе фреймворк не будет знать, где хранить результаты, или даже выполнять вычисления.
> При вызове операции между тензорами с разными устройствами GPU вызывается исключение.
> Решение: копирование тензора на другое устройство
> ![[transfer device.png]]
> `Z = X.cuda(1)` и выполнение операции!
> - Если мы пытаемся переместить тензор на то устройство, где он уже находится, ничего не произойдет. Проверка: `Z.cuda(1) is Z # True`

- Передача данных между устройствами часто происходит медленее, чем сами вычисления; усложняет распараллеливание