{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03fcfdf2-9341-43da-a3a6-2e5be4164cbb",
   "metadata": {},
   "source": [
    "# Midterm Task: Hyperspectral Image Segmentation\n",
    "\n",
    "## Task Overview\n",
    "\n",
    "For this question, your task is to perform **image segmentation** on a hyperspectral image. You will be provided with preprocessed hyperspectral data and corresponding ground truth labels. Your goal is to segment the image into meaningful regions based on the spectral characteristics of the pixels. Once you have completed the segmentation, you will evaluate the performance of your results by comparing against the ground truth labels.\n",
    "\n",
    "## Hyperspectral Data Explanation\n",
    "\n",
    "The hyperspectral image consists of 307x307 pixels, with each pixel having 162 spectral bands. These spectral bands represent different wavelengths across the electromagnetic spectrum, allowing for detailed analysis of the scene beyond the visible range.\n",
    "\n",
    "Each pixel corresponds to one of the following classes:\n",
    "- **#0**: Asphalt Road\n",
    "- **#1**: Grass\n",
    "- **#2**: Tree\n",
    "- **#3**: Roof\n",
    "- **#4**: Metal\n",
    "- **#5**: Dirt\n",
    "\n",
    "The ground truth labels represent the true class for each pixel, and your task is to segment the image based on these categories.\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Load the Data**: Use the provided Python code to load the preprocessed data (`X.npy` for the hyperspectral data and `y.npy` for the ground truth labels).\n",
    "   \n",
    "2. **Segmentation**: Perform segmentation on the hyperspectral data. You may explore any technique you deem appropriate for this task.\n",
    "\n",
    "3. **Evaluation**: After performing segmentation, use the provided evaluation script to compare your segmentation results with the ground truth labels using **Adjusted Rand Index (ARI)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac92678-b7fc-4d16-ab72-efdf96974940",
   "metadata": {},
   "source": [
    "## **Step 1: Load the Data**\n",
    "\n",
    "Use the following Python code to load the hyperspectral data and the ground truth labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7612a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luzinsan/Documents/Obsidian/ML/Innopolis/material/1 semester/HDDA/labs/midterm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luzinsan/.cache/pypoetry/virtualenvs/ml-venv-uqlfkjfM-py3.11/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/luzinsan/Documents/Obsidian/ML/Innopolis/material/1 semester/HDDA/labs/midterm/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8487ba4b-7395-474e-b807-1e06c9849677",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './y.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the hyperspectral data (X) and ground truth labels (y)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./y.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (307, 307)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./X.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Shape: (307, 307, 162)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Display the ground truth labels to visualize the classes\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/ml-venv-uqlfkjfM-py3.11/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './y.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the hyperspectral data (X) and ground truth labels (y)\n",
    "y = np.load(\"./y.npy\")  # Shape: (307, 307)\n",
    "X = np.load(\"./X.npy\")  # Shape: (307, 307, 162)\n",
    "\n",
    "# Display the ground truth labels to visualize the classes\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title('Ground Truth Labels')\n",
    "plt.imshow(y, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e8c68-2211-437c-843a-565aa7fae95d",
   "metadata": {},
   "source": [
    "## **Step 2: Perform Segmentation**\n",
    "\n",
    "**Your Task**: Implement a segmentation method on the hyperspectral image `image_reshaped`. You may choose any method that you find appropriate.\n",
    "\n",
    "The variable `image_reshaped` has the shape `(307, 307, 162)`, where the first two dimensions correspond to the pixel grid and the last dimension represents the 162 spectral bands for each pixel. \n",
    "\n",
    "You need to output a 2D array (segment map) of the same shape as the ground truth labels `(307, 307)` where each pixel is assigned a class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f217ec4d-7484-42fc-81ce-c91cda23692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your segmentation code here\n",
    "# Segment the image_reshaped into labels\n",
    "# segmented_labels = ...\n",
    "\n",
    "# Example:\n",
    "# segmented_labels = some_segmentation_function(image_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d0bd0-4665-4b0b-b7e2-6d8af912f707",
   "metadata": {},
   "source": [
    "## **Step 3: Evaluate the Segmentation**\n",
    "\n",
    "Once you have segmented the image, you need to evaluate the quality of your segmentation by comparing it with the ground truth labels. It's up to you to choose the appropriate metric to compare your segmentation results with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e8278-2d35-4d71-98ff-1990868e377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your chosen metric from sklearn or another library\n",
    "# Example: from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "# Print the chosen evaluation metric\n",
    "print(f\"Your Chosen Metric Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e28e0b-ab63-4e0c-9f0d-ee01dddc3d7d",
   "metadata": {},
   "source": [
    "## Deliverables:\n",
    "- Your ipynb for the segmentation task with the outputs.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
